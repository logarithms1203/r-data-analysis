#install.packages("caret")
crime_train <- crime_incidents_df[1:25478, ]
crime_test <- crime_incidents_df[-(1:25478),]
crime_train$OFFENSE <- as.factor(crime_train$OFFENSE)
colnames(crime_train)
model_fit_full <- glm(OFFENSE ~ Month + Hour + LONGITUDE + LATITUDE, data = crime_train, family = binomial)
model_fit_null <- glm(OFFENSE ~ 1, data = crime_train, family = binomial)
model_fit_best <- stepAIC(model_fit_full, scope = list(lower = model_fit_null, upper = model_fit_full),
direction = "both", trace = 0)
summary(model_fit_best)
crime_incidents_df$OFFENSE_BIN <- ifelse(crime_incidents_df$OFFENSE == "THEFT", 1, 0)
View(crime_incidents_df)
#install.packages("caret")
crime_train <- crime_incidents_df[1:25478, ]
crime_test <- crime_incidents_df[-(1:25478),]
crime_incidents_df$OFFENSE_BIN <- ifelse(crime_incidents_df$OFFENSE == "THEFT", 1, 0)
crime_train$OFFENSE <- as.factor(crime_train$OFFENSE)
colnames(crime_train)
model_fit_full <- glm(OFFENSE ~ Month + Hour + LONGITUDE + LATITUDE, data = crime_train, family = binomial)
model_fit_null <- glm(OFFENSE ~ 1, data = crime_train, family = binomial)
model_fit_best <- stepAIC(model_fit_full, scope = list(lower = model_fit_null, upper = model_fit_full),
direction = "both", trace = 0)
summary(model_fit_best)
model_fit_full <- glm(OFFENSE_BINARY ~ Month + Hour + LONGITUDE + LATITUDE, data = crime_train, family = binomial)
crime_incidents_df$OFFENSE_BINARY <- ifelse(crime_incidents_df$OFFENSE == "THEFT", 1, 0)
crime_train$OFFENSE <- as.factor(crime_train$OFFENSE)
colnames(crime_train)
model_fit_full <- glm(OFFENSE_BINARY ~ Month + Hour + LONGITUDE + LATITUDE, data = crime_train, family = binomial)
model_fit_null <- glm(OFFENSE_BINARY ~ 1, data = crime_train, family = binomial)
#install.packages("caret")
crime_train <- crime_incidents_df[1:25478, ]
crime_test <- crime_incidents_df[-(1:25478),]
crime_incidents_df$OFFENSE_BINARY <- ifelse(crime_incidents_df$OFFENSE == "THEFT", 1, 0)
crime_train <- crime_incidents_df[1:25478, ]
crime_test <- crime_incidents_df[-(1:25478),]
crime_train$OFFENSE <- as.factor(crime_train$OFFENSE)
colnames(crime_train)
model_fit_full <- glm(OFFENSE_BINARY ~ Month + Hour + LONGITUDE + LATITUDE, data = crime_train, family = binomial)
model_fit_null <- glm(OFFENSE_BINARY ~ 1, data = crime_train, family = binomial)
model_fit_best <- stepAIC(model_fit_full, scope = list(lower = model_fit_null, upper = model_fit_full),
direction = "both", trace = 0)
summary(model_fit_best)
library(nnet)
#install.packages("caret")
crime_train <- crime_incidents_df[1:25478, ]
crime_test <- crime_incidents_df[-(1:25478),]
crime_train$OFFENSE <- as.factor(crime_train$OFFENSE)
colnames(crime_train)
model_fit_full <- multinom(OFFENSE ~ Month + Hour + LONGITUDE + LATITUDE, data = crime_train, family = binomial)
model_fit_null <- multinom(OFFENSE ~ 1, data = crime_train, family = binomial)
model_fit_best <- stepAIC(model_fit_full, scope = list(lower = model_fit_null, upper = model_fit_full),
direction = "both", trace = 0)
summary(model_fit_best)
confusionMatrix(data = pi_hat_test, reference = crime_test$OFFENSE)
pi_hat_test <- predict(model_fit_best, newdata = crime_test)
confusionMatrix(data = pi_hat_test, reference = crime_test$OFFENSE)
preds <- predict(model_fit_best, newdata = crime_test)
confusionMatrix(preds, crime_test$OFFENSE)
pi_hat_test <- predict(model_fit_best, newdata = crime_test)
pi_hat_test <- predict(model_fit_best, newdata = crime_test)
confusionMatrix(data = pi_hat_test, reference = crime_test$OFFENSE)
pi_hat_test <- predict(model_fit_best, newdata = crime_test)
confusionMatrix(data = pi_hat_test, reference = crime_test$OFFENSE)
predictor <- factor(pi_hat_test, levels = levels(crime_train$OFFENSE))
truth <- factor(crime_test$OFFENSE, levels = levels(crime_test$OFFENSE))
confusionMatrix(predictor, truth)
#install.packages("caret")
crime_train <- crime_incidents_df[1:25000, ]
crime_test <- crime_incidents_df[-(1:25000),]
crime_train$OFFENSE <- as.factor(crime_train$OFFENSE)
colnames(crime_train)
model_fit_full <- multinom(OFFENSE ~ Month + Hour + LONGITUDE + LATITUDE, data = crime_train, family = binomial)
model_fit_null <- multinom(OFFENSE ~ 1, data = crime_train, family = binomial)
model_fit_best <- stepAIC(model_fit_full, scope = list(lower = model_fit_null, upper = model_fit_full),
direction = "both", trace = 0)
summary(model_fit_best)
# Chunk 1: setup
# This is the setup chunk
#  Here you can set global options for the entire document
library(knitr) # I recommend doing this
# Although you can call functions from a library using the following notation
#  without loading the entire library.
knitr::opts_chunk$set(echo = TRUE,
comment = NA, # Recommended
fig.path = "./figures/",  # Store all figures here in relative path
fig.align = "center",
fig.width = 7,
fig.height = 7,
message = FALSE, # Turn off load messages
warning = FALSE # Turn off warnings,
)
# Chunk 2: appendix-load-packages
# You should set your working directory at the very beginning of your R Markdown file
setwd("/Users/logansalinas/Desktop/CMDA 3654/Project 1")
# You should load all of the libraries that you plan to use here unless you plan
#  on using the notation library_name::function_name()
library(tidyverse)
library(pander)  # We used pander here, but some alternative libraries are below:
library(xtable)
library(kableExtra)
library(knitr)
# Chunk 3: appendix-load-wide-summary-table
# We first read in the crime_incidents csv file and store it as a data frame
crime_incidents_df <- read.csv("Crime_Incidents_in_2017.csv")
# We make a new column called "Month", and extract the month from the REPORT_DAT variable and place in the Month column
crime_incidents_df$Month <- month(crime_incidents_df$REPORT_DAT, label = TRUE)
# We create an entirely new table that summarizes the months and offenses together
wide_summary_table <- pivot_wider(summarize(group_by(crime_incidents_df, Month, OFFENSE),
Total = n()),
names_from = OFFENSE, values_from = Total, values_fill = 0)
# We use kable() to give the table a better format
kbl(wide_summary_table, caption = "Total Amount of Crimes Reported Each Month per Offense") %>%
kable_styling(latex_options = c("hold_position", "scale_down"))
# Chunk 4: appendix-plot-bar-graph
# We use pivot_longer() to create a new data frame with the variables month, Offenses, and Number of Crimes reported for those offenses.
long_summary_table <- pivot_longer(wide_summary_table,
col = -Month,
names_to = "Offenses",
values_to = "Number_of_Times_Crimes_Reported")
# We use ggplot() and geom_bar() to create a bar graph of the number of crimes reported for each crime in each month.
# We use aes() to give the plot object x, y and fill values and geom_bar() to make the plot object a bar plot object.
ggplot(data = long_summary_table,
aes(x = Month, y = Number_of_Times_Crimes_Reported, fill = Offenses)) +
geom_bar(stat = "identity") +
labs(title = "Crimes Reported Each Month and Offense",
x = "Month",
y = "Number of Crimes Reported")
# Chunk 5: appendix-load-univariate-table
# We use summarize() to get the summary statistic of the longitude and latitude variables, then we store those values onto a table
univariate_summary_table <- summarize(crime_incidents_df,
longitude_min = min(LONGITUDE),
longitude_max = max(LONGITUDE),
longitude_mean = mean(LONGITUDE),
longitude_median = median(LONGITUDE),
longitude_sd = sd(LONGITUDE),
latitude_min = min(LATITUDE),
latitude_max = max(LATITUDE),
latitude_mean = mean(LATITUDE),
latitude_median = median(LATITUDE),
latitude_sd = sd(LATITUDE))
# Next we use pivot_longer to make the table horizontal, make it more readable.
univariate_summary_table <- pivot_longer(univariate_summary_table, everything())
# After we use kable() to properly format the table and give the table a caption.
kable(univariate_summary_table, caption = "Univariate Summary Table of Longitude and Latitude")
# Chunk 6: appendix-plot-scatterplot
# We use ggplot() and geom_point() to create the plot object and make the plot object a scatter plot.
# We use aes() to give the plot object data to plot and labs() to give the plot labels.
ggplot(crime_incidents_df, aes(x = LONGITUDE, y = LATITUDE)) + geom_point(aes(color = OFFENSE)) +
labs(title = "Crime Locations in DC",
x = "Longitude",
y = "Latitude")
# Chunk 7: appendix-load-bivariate-summary-table
# We extract the hour from the entries in the variable "REPORT_DAT" and store those entries in a new Hour variable.
crime_incidents_df$Hour <- hour(crime_incidents_df$REPORT_DAT)
# We calculate the summary statistics of the Hour per Shift, this is by using summarize(), group_by(), which groups the data set itself and the SHIFT variable, then summarize() produces the results for the data set and SHIFT variable. We calculate the the summary statistics for the SHIFT variable.
summary_table <- summarize(group_by(crime_incidents_df, SHIFT),
min_hour = min(Hour),
lower_quantile_hour = quantile(Hour, 0.25),
median_hour = median(Hour),
upper_quantile_hour = quantile(Hour, 0.75),
max_hour = max(Hour),
mean_hour = mean(Hour),
sd_hour = sd(Hour))
# We use kable() to properly format the table we created and give it a caption
kable(summary_table, caption = "Bivariate Summary Table of Hours per Shift")
# Chunk 8: appendix-plot-boxplot
# We use ggplot() and geom_boxplot() to create a plot object with the SHIFT and hour variables from the data set.
# Then we use geom_boxplot() to make the plot object a boxplot object with its labels included.
ggplot(crime_incidents_df,
aes(x = SHIFT,
y = Hour,
color = SHIFT)) +
geom_boxplot() +
labs(title = "Crimes Reported Hour Distribution per Shift",
x = "Police Shift when Crime was reported",
y = "Hour of the report")
# Chunk 9: appendix-load-bivariate-summary-table-2
# We use summarize() and group() and include the crime data set, variable Month and Shift to create a table that contains
# the information of the amount of crimes reported for each type of offense for each month.
month_shift_trend <- summarize(group_by(crime_incidents_df, Month, SHIFT), n = n())
# We use summarize() and group() and include the crime data set, variable n and Shift to find the summary statistics of the number of crimes reported per shift.
summary_table <- summarize(group_by(month_shift_trend, SHIFT),
min_reports = min(n),
max_reports = max(n),
mean_reports = mean(n),
median_reports = median(n),
sd_reports = sd(n))
# We use kable() to properly format the table we created and give it a caption
kable(summary_table, caption = "Bivariate Summary Table of Reports per Shift")
# Chunk 10: appendix-plot-trend-line
# We use ggplot() along with the month_shift_trend data set, variables Month and
# n (number of crimes committed for each month) to create a trend line graph.
# labs() is used to give the graph its labels etc.
ggplot(month_shift_trend,
aes(x = Month,
y = n,
color = SHIFT,
group = SHIFT)) +
geom_line() +
labs(title = "Crime Month Trend by Shift",
x = "Month",
y = "Number of Crimes Reported")
# Chunk 11
library(ISLR)
library(MASS)
library(nnet)
#install.packages("caret")
crime_train <- crime_incidents_df[1:25000, ]
crime_test <- crime_incidents_df[-(1:25000),]
crime_train$OFFENSE <- as.factor(crime_train$OFFENSE)
colnames(crime_train)
model_fit_full <- multinom(OFFENSE ~ Month + Hour + LONGITUDE + LATITUDE, data = crime_train, family = binomial)
model_fit_null <- multinom(OFFENSE ~ 1, data = crime_train, family = binomial)
model_fit_best <- stepAIC(model_fit_full, scope = list(lower = model_fit_null, upper = model_fit_full),
direction = "both", trace = 0)
summary(model_fit_best)
# Chunk 12
View(crime_incidents_df)
table_crime_frequency <- xtabs(~ OFFENSE + Month)
table_crime_frequency <- xtabs(~ OFFENSE + Month, data = crime_incidents_df)
table_crime_frequency
table_crime <- xtabs(~ OFFENSE + Month, data = crime_incidents_df)
table_crime
prop.table(table_crime, 1)
table_crime <- xtabs(~ OFFENSE + Month, data = crime_incidents_df)
table_crime
prop.table(table_crime, 1)
chisq.test(table_crime)
table_crime <- xtabs(~ OFFENSE + Month, data = crime_incidents_df)
table_crime
prop.table(table_crime, 1)
chisq.test(table_crime)
table_crime <- xtabs(~ OFFENSE + Month, data = crime_incidents_df)
table_crime
prop.table(table_crime, 1)
chisq.test(table_crime)
mosaic(table_crime, shade = T)
library(mosaic)
library(mosaic)
install.packages("mosaic")
#install.packages("mosaic")
library(mosaic)
table_crime <- xtabs(~ OFFENSE + Month, data = crime_incidents_df)
table_crime
prop.table(table_crime, 1)
chisq.test(table_crime)
mosaic(table_crime, shade = T)
assocplot(table_crime, shade = T)
mosaic(table_crime, shade = T)
assocplot(table_crime)
mosaicplot(table_crime, shade = T)
library(vcd)
assoc(table_crime, shade = T)
mosaicplot(table_crime, shade = T)
assoc(table_crime, shade = T, cex.axis = 0.7)
mosaicplot(table_crime, las = 2, cex.axis = 0.7)
assocplot(table_crime, las = 2, cex.axis = 0.7)
mosaic(table_crime, las = 2, cex.axis = 0.7)
mosaicplot(table_crime, las = 2, cex.axis = 0.7)
mosaicplot(table_crime, shade = TRUE, las = 2, cex.axis = 0.7)
crime_incident_scaled <- scale(crime_incidents_df)
crime_incident_small_df <- select(crime_incidents_df, crime_incidents_df$LONGITUDE, crime_incidents_df$LATITUDE)
crime_incident_small_df <- select(crime_incidents_df, LONGITUDE, LATITUDE)
library(dplyr)
crime_incident_small_df <- select(crime_incidents_df, LONGITUDE, LATITUDE)
crime_incident_small_df <- dyplr::select(crime_incidents_df, LONGITUDE, LATITUDE)
library(dplyr)
crime_incident_small_df <- dplyr::select(crime_incidents_df, LONGITUDE, LATITUDE)
crime_incident_small_df <- select(crime_incidents_df, LONGITUDE, LATITUDE)
crime_incident_small_df <- dplyr::select(crime_incidents_df, LONGITUDE, LATITUDE)
View(crime_incident_small_df)
crime_incident_scaled <- scale(crime_incident_small_df)
k_means_clustering <- kmeans(crime_incident_scaled, centers = 2, nstart = 25)
fviz_nbclust(crime_incident_scaled, kmeans, method = "wss")
library(cluster)
library(factoextra)
fviz_nbclust(crime_incident_scaled, kmeans, method = "wss")
fviz_cluster(k_means_clustering, data = crime_incident_small_df, geom = "point")
k_means_clustering <- kmeans(crime_incident_scaled, centers = 3, nstart = 25)
fviz_cluster(k_means_clustering, data = crime_incident_small_df, geom = "point")
k_means_clustering <- kmeans(crime_incident_scaled, centers = 4, nstart = 25)
fviz_cluster(k_means_clustering, data = crime_incident_small_df, geom = "point")
k_means_clustering <- kmeans(crime_incident_scaled, centers = 5, nstart = 25)
fviz_cluster(k_means_clustering, data = crime_incident_small_df, geom = "point")
k_means_clustering <- kmeans(crime_incident_scaled, centers = 6, nstart = 25)
fviz_cluster(k_means_clustering, data = crime_incident_small_df, geom = "point")
k_means_clustering <- kmeans(crime_incident_scaled, centers = 20, nstart = 25)
fviz_cluster(k_means_clustering, data = crime_incident_small_df, geom = "point")
k_means_clustering
k_means_clustering <- kmeans(crime_incident_scaled, centers = 100, nstart = 25)
k_means_clustering
fviz_cluster(k_means_clustering, data = crime_incident_small_df, geom = "point")
k_means_clustering <- kmeans(crime_incident_scaled, centers = 8, nstart = 25)
k_means_clustering
fviz_cluster(k_means_clustering, data = crime_incident_small_df, geom = "point")
k_means_clustering <- kmeans(crime_incident_scaled, centers = 8, nstart = 25)
fviz_cluster(k_means_clustering, data = crime_incident_small_df)
fviz_nbclust(crime_incident_scaled, kmeans, method = "wss")
mem.maxVSize(crime_incident_scaled)
fviz_nbclust(crime_incident_scaled[1:5000], kmeans, method = "wss")
fviz_nbclust(crime_incident_scaled[1:5000, ], kmeans, method = "wss")
fviz_nbclust(crime_incident_scaled[sample(1:nrow(crime_incident_scaled), 5000), ], kmeans, method = "wss")
fviz_nbclust(crime_incident_scaled[sample(1:nrow(crime_incident_scaled), 5000), ], kmeans, method = "wss")
k_means_clustering
# k_means_clustering
fviz_cluster(k_means_clustering, data = crime_incident_small_df, geom = "point")
library(dplyr)
library(cluster)
library(factoextra)
crime_incident_small_df <- dplyr::select(crime_incidents_df, LONGITUDE, LATITUDE)
crime_incident_scaled <- scale(crime_incident_small_df)
fviz_nbclust(crime_incident_scaled[sample(1:nrow(crime_incident_scaled), 5000), ], kmeans, method = "wss")
#mem.maxVSize(crime_incident_scaled)
k_means_clustering <- kmeans(crime_incident_scaled, centers = 4, nstart = 25)
# k_means_clustering
fviz_cluster(k_means_clustering, data = crime_incident_small_df, geom = "point")
crime_incident_small_df$clustering <- k_means_clustering
nrow(crime_incident_small_df)           # should equal
length(k_means_clustering$cluster)      # this
View(k_means_clustering)
View(k_means_clustering)
crime_incident_small_df$clustering <- k_means_clustering$cluster
crime_incidents_d$clusters <- k_means_clustering$cluster
crime_incidents_df$clusters <- k_means_clustering$cluster
library(dplyr)
library(cluster)
library(factoextra)
crime_incident_small_df <- dplyr::select(crime_incidents_df, LONGITUDE, LATITUDE)
crime_incident_scaled <- scale(crime_incident_small_df)
fviz_nbclust(crime_incident_scaled[sample(1:nrow(crime_incident_scaled), 5000), ], kmeans, method = "wss")
#mem.maxVSize(crime_incident_scaled)
k_means_clustering <- kmeans(crime_incident_scaled, centers = 4, nstart = 25)
# k_means_clustering
fviz_cluster(k_means_clustering, data = crime_incident_small_df, geom = "point")
crime_incident_small_df$cluster <- k_means_clustering$cluster
crime_incidents_df$clusters <- k_means_clustering$cluster
crime_incidents_df %>%
dplyr::group_by(cluster, OFFENSE) %>%
dplyr::summarise(count = n(), .groups = "drop") %>%
dplyr::arrange(cluster, desc(count))
library(dplyr)
library(cluster)
library(factoextra)
crime_incident_small_df <- dplyr::select(crime_incidents_df, LONGITUDE, LATITUDE)
crime_incident_scaled <- scale(crime_incident_small_df)
fviz_nbclust(crime_incident_scaled[sample(1:nrow(crime_incident_scaled), 5000), ], kmeans, method = "wss")
#mem.maxVSize(crime_incident_scaled)
k_means_clustering <- kmeans(crime_incident_scaled, centers = 4, nstart = 25)
# k_means_clustering
fviz_cluster(k_means_clustering, data = crime_incident_small_df, geom = "point")
crime_incident_small_df$clusters <- k_means_clustering$clusters
crime_incidents_df$clusters <- k_means_clustering$clusters
crime_incidents_df %>%
dplyr::group_by(cluster, OFFENSE) %>%
dplyr::summarise(count = n(), .groups = "drop") %>%
dplyr::arrange(cluster, desc(count))
crime_incidents_df %>%
dplyr::group_by(cluster, OFFENSE) %>%
dplyr::summarise(count = n(), .groups = "drop") %>%
dplyr::arrange(clusters, desc(count))
crime_incidents_df %>%
dplyr::group_by(clusters, OFFENSE) %>%
dplyr::summarise(count = n(), .groups = "drop") %>%
dplyr::arrange(clusters, desc(count))
library(dplyr)
library(cluster)
library(factoextra)
crime_incident_small_df <- dplyr::select(crime_incidents_df, LONGITUDE, LATITUDE)
crime_incident_scaled <- scale(crime_incident_small_df)
fviz_nbclust(crime_incident_scaled[sample(1:nrow(crime_incident_scaled), 5000), ], kmeans, method = "wss")
#mem.maxVSize(crime_incident_scaled)
k_means_clustering <- kmeans(crime_incident_scaled, centers = 4, nstart = 25)
# k_means_clustering
fviz_cluster(k_means_clustering, data = crime_incident_small_df, geom = "point")
crime_incident_small_df$clusters <- k_means_clustering$clusters
crime_incidents_df$clusters <- k_means_clustering$clusters
crime_incidents_df %>%
dplyr::group_by(clusters, OFFENSE) %>%
dplyr::summarise(count = n(), .groups = "drop") %>%
dplyr::arrange(clusters, desc(count))
crime_incident_small_df$clusters <- k_means_clustering$clusters
crime_incidents_df$clusters <- k_means_clustering$clusters
k_means_clustering <- kmeans(crime_incident_scaled, centers = 4, nstart = 25)
View(k_means_clustering)
crime_incident_small_df$clusters <- k_means_clustering$cluster
crime_incidents_df$clusters <- k_means_clustering$clusters
crime_incident_small_df$clusters <- k_means_clustering$cluster
crime_incidents_df$clusters <- k_means_clustering$cluster
crime_incidents_df %>%
dplyr::group_by(clusters, OFFENSE) %>%
dplyr::summarise(count = n(), .groups = "drop") %>%
dplyr::arrange(clusters, desc(count))
print(n = 25
crime_clust_tab_count <- arrange(summarize(group_by(crime_incidents_df, clusters, OFFENSE),
crime_clust_tab_count <- arrange(summarize(group_by(crime_incidents_df, clusters, OFFENSE),
.groups = "drop"), clusters, desc(count))
crime_clust_tab_count <- arrange(summarize(group_by(crime_incidents_df, count = n(),clusters, OFFENSE),
.groups = "drop"), clusters, desc(count))
crime_clust_tab_count
crime_clust_tab_count <- arrange(summarise(group_by(crime_incidents_df, clusters, OFFENSE),
count = n(), .groups = "drop"), clusters, desc(count))
crime_clust_tab_count
kbl(crime_clust_tab_count) %>%
kable_styling(latex_options = c("hold_position", "scale_down"))
kbl(crime_clust_tab_count) %>%
kable_styling(latex_options = c("scale_down"))
library(dplyr)
library(cluster)
library(factoextra)
crime_incident_small_df <- dplyr::select(crime_incidents_df, LONGITUDE, LATITUDE)
crime_incident_scaled <- scale(crime_incident_small_df)
fviz_nbclust(crime_incident_scaled[sample(1:nrow(crime_incident_scaled), 5000), ], kmeans, method = "wss")
#mem.maxVSize(crime_incident_scaled)
k_means_clustering <- kmeans(crime_incident_scaled, centers = 4, nstart = 25)
# k_means_clustering
fviz_cluster(k_means_clustering, data = crime_incident_small_df, geom = "point")
crime_incident_small_df$clusters <- k_means_clustering$cluster
crime_incidents_df$clusters <- k_means_clustering$cluster
crime_clust_tab_count <- arrange(summarise(group_by(crime_incidents_df, clusters, OFFENSE),
count = n(), .groups = "drop"), clusters, desc(count))
kbl(crime_clust_tab_count) %>%
kable_styling(latex_options = c("HOLD_position", "scale_down"))
#install.packages("caret")
crime_train <- crime_incidents_df[1:25000, ]
crime_test <- crime_incidents_df[-(1:25000),]
crime_train$OFFENSE <- as.factor(crime_train$OFFENSE)
colnames(crime_train)
model_fit_full <- multinom(OFFENSE ~ Month + Hour + LONGITUDE + LATITUDE, data = crime_train, family = binomial)
model_fit_full <- multinom(OFFENSE ~ Month + Hour + LONGITUDE + LATITUDE, data = crime_train, family = multinom)
model_fit_null <- multinom(OFFENSE ~ 1, data = crime_train, family = binomial)
model_fit_best <- stepAIC(model_fit_full, scope = list(lower = model_fit_null, upper = model_fit_full),
direction = "both", trace = 0)
summary(model_fit_best)
library(ISLR)
library(MASS)
library(nnet)
library(vcd)
library(mosaic)
#install.packages("caret")
crime_train <- crime_incidents_df[1:25000, ]
crime_test <- crime_incidents_df[-(1:25000),]
crime_train$OFFENSE <- as.factor(crime_train$OFFENSE)
# colnames(crime_train)
model_fit_full <- multinom(OFFENSE ~ Month + Hour + LONGITUDE + LATITUDE, data = crime_train, family = binomial)
model_fit_null <- multinom(OFFENSE ~ 1, data = crime_train, family = binomial)
model_fit_best <- stepAIC(model_fit_full, scope = list(lower = model_fit_null, upper = model_fit_full),
direction = "both", trace = 0)
summary(model_fit_best)
getwd()
# We use pivot_longer() to create a new data frame with the variables month, Offenses, and Number of Crimes reported for those offenses.
long_summary_table <- pivot_longer(wide_summary_table,
col = -Month,
names_to = "Offenses",
values_to = "Number_of_Times_Crimes_Reported")
# We use ggplot() and geom_bar() to create a bar graph of the number of crimes reported for each crime in each month.
# We use aes() to give the plot object x, y and fill values and geom_bar() to make the plot object a bar plot object.
ggplot(data = long_summary_table,
aes(x = Month, y = Number_of_Times_Crimes_Reported, fill = Offenses)) +
geom_bar(stat = "identity") +
labs(title = "Crimes Reported Each Month and Offense",
x = "Month",
y = "Number of Crimes Reported")
View(k_means_clustering)
# Then we format the table using kbl(), using kable_styling() to hold the table
# in place.
kbl(t(crime_clust_tab_count)) %>%
kable_styling(latex_options = c("HOLD_position", "scale_down"), font_size = 8)
# Then we format the table using kbl(), using kable_styling() to hold the table
# in place.
kbl(t(crime_clust_tab_count)) %>%
kable_styling(latex_options = c("HOLD_position", "scale_down")) %>%
landscape()
library(ISLR)
library(MASS)
library(nnet)
library(vcd)
library(mosaic)
#install.packages("caret")
crime_train <- crime_incidents_df[1:25000, ]
crime_test <- crime_incidents_df[-(1:25000),]
crime_train$OFFENSE <- as.factor(crime_train$OFFENSE)
# colnames(crime_train)
model_fit_full <- glm(OFFENSE ~ Month + Hour + LONGITUDE + LATITUDE, data = crime_train, family = binomial)
model_fit_null <- glm(OFFENSE ~ 1, data = crime_train, family = binomial)
model_fit_best <- stepAIC(model_fit_full, scope = list(lower = model_fit_null, upper = model_fit_full),
direction = "both", trace = 0)
model_fit_best
model_fit_best
model_fit_best
summary(model_fit_best)
# Finally we use summary() on the best fitted model to
summary(model_fit_best)
# First thing to do was to use 70-80% of the data as training data, and leave
# the rest as testing data.
crime_train <- crime_incidents_df[1:25000, ]
crime_test <- crime_incidents_df[-(1:25000),]
# Then we made the OFFENSE variable a factor type
crime_train$OFFENSE <- as.factor(crime_train$OFFENSE)
# We are creating the full model, using OFFENSE as the response variable, and
# Month, Hour, LONGITUDE AND LATITUDE as the predictor variables.
model_fit_full <- glm(OFFENSE ~ Month + Hour, data = crime_train, family = binomial)
# We are creating a null model, only using OFFENSE as teh response variable,
# no predictor variables are included
model_fit_null <- glm(OFFENSE ~ 1, data = crime_train, family = binomial)
# Then we create the best fitted model using the stepAIC()
model_fit_best <- stepAIC(model_fit_full, scope = list(lower = model_fit_null, upper = model_fit_full),
direction = "both", trace = 0)
# model_fit_best
```
# Finally we use summary() on the best fitted model to display the results of the
# model
summary(model_fit_best)
